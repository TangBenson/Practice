{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50beedd9-bc34-46ca-b836-653b69fc3430",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor on Bike Sharing Dataset\n",
    "#### 來自kaggle最多投票的專案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c2c322-e7ea-4bad-953b-235a91178d53",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85061b9-aa17-4f70-86be-faa9e1b2a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manuipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# modeling utilities\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train_test_split\n",
    "\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting parameters tuning\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk')\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (30, 10),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d5942-d908-49f2-b7a7-fc0273d872d7",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99aeccb-2c86-45a1-aebc-67647772a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df = pd.read_csv(\"../input/bike-sharing-dataset/hour.csv\")\n",
    "hour_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1b64f-ce3d-4f00-961c-7fa44d05467c",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2d504-c058-43d6-a0ee-2ec6b03b0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns names to more readable names\n",
    "hour_df.rename(columns={'instant':'rec_id',\n",
    "                        'dteday':'datetime',\n",
    "                        'holiday':'is_holiday',\n",
    "                        'workingday':'is_workingday',\n",
    "                        'weathersit':'weather_condition',\n",
    "                        'hum':'humidity',\n",
    "                        'mnth':'month',\n",
    "                        'cnt':'total_count',\n",
    "                        'hr':'hour',\n",
    "                        'yr':'year'},inplace=True)\n",
    "\n",
    "###########################\n",
    "# Setting proper data types\n",
    "###########################\n",
    "# date time conversion\n",
    "hour_df['datetime'] = pd.to_datetime(hour_df.datetime)\n",
    "\n",
    "# categorical variables\n",
    "hour_df['season'] = hour_df.season.astype('category')\n",
    "hour_df['is_holiday'] = hour_df.is_holiday.astype('category')\n",
    "hour_df['weekday'] = hour_df.weekday.astype('category')\n",
    "hour_df['weather_condition'] = hour_df.weather_condition.astype('category')\n",
    "hour_df['is_workingday'] = hour_df.is_workingday.astype('category')\n",
    "hour_df['month'] = hour_df.month.astype('category')\n",
    "hour_df['year'] = hour_df.year.astype('category')\n",
    "hour_df['hour'] = hour_df.hour.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe4fa4-0bce-4db2-99a5-27a81316d346",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d98c9-4393-406c-bef1-e2a3ec0c8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining categorical variables encoder method\n",
    "def fit_transform_ohe(df,col_name):\n",
    "    \"\"\"This function performs one hot encoding for the specified\n",
    "column.\n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        col_name: the column to be one hot encoded\n",
    "    Returns:\n",
    "        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series\n",
    "    \"\"\"\n",
    "    # label encode the column\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le_labels = le.fit_transform(df[col_name])\n",
    "    df[col_name+'_label'] = le_labels\n",
    "    # one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    return le,ohe,features_df\n",
    "\n",
    "# given label encoder and one hot encoder objects, \n",
    "# encode attribute to ohe\n",
    "def transform_ohe(df,le,ohe,col_name):\n",
    "    \"\"\"This function performs one hot encoding for the specified\n",
    "        column using the specified encoder objects.\n",
    "\n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        le(Label Encoder): the label encoder object used to fit label encoding\n",
    "        ohe(One Hot Encoder): the onen hot encoder object used to fit one hot encoding\n",
    "        col_name: the column to be one hot encoded\n",
    "\n",
    "    Returns:\n",
    "        tuple: transformed column as pandas Series\n",
    "\n",
    "    \"\"\"\n",
    "    # label encode\n",
    "    col_labels = le.transform(df[col_name])\n",
    "    df[col_name+'_label'] = col_labels\n",
    "    \n",
    "    # ohe \n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a87aa5-931a-4bda-ae0d-a73b18132e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and testing sets\n",
    "X, X_test, y, y_test = train_test_split(hour_df.iloc[:,0:-3],\n",
    "                                        hour_df.iloc[:,-1],\n",
    "                                        test_size=0.33,\n",
    "                                        random_state=42)\n",
    "X.reset_index(inplace=True)\n",
    "y = y.reset_index()\n",
    "\n",
    "X_test.reset_index(inplace=True)\n",
    "y_test = y_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2cc56-06e3-4629-b4f3-4263748601cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding all the categorical features\n",
    "cat_attr_list = ['season','is_holiday',\n",
    "                 'weather_condition','is_workingday',\n",
    "                 'hour','weekday','month','year']\n",
    "# though we have transformed all categoricals into their one-hot encodings, note that ordinal\n",
    "# attributes such as hour, weekday, and so on do not require such encoding.\n",
    "numeric_feature_cols = ['temp','humidity','windspeed',\n",
    "                        'hour','weekday','month','year']\n",
    "subset_cat_features =  ['season','is_holiday','weather_condition','is_workingday']\n",
    "\n",
    "###############\n",
    "# Train dataset\n",
    "###############\n",
    "encoded_attr_list = []\n",
    "for col in cat_attr_list:\n",
    "    return_obj = fit_transform_ohe(X,col)\n",
    "    encoded_attr_list.append({'label_enc':return_obj[0],\n",
    "                              'ohe_enc':return_obj[1],\n",
    "                              'feature_df':return_obj[2],\n",
    "                              'col_name':col})\n",
    "\n",
    "\n",
    "feature_df_list  = [X[numeric_feature_cols]]\n",
    "feature_df_list.extend([enc['feature_df'] \\\n",
    "                        for enc in encoded_attr_list \\\n",
    "                        if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "train_df_new = pd.concat(feature_df_list, axis=1)\n",
    "print(\"Train dataset shape::{}\".format(train_df_new.shape))\n",
    "print(train_df_new.head())\n",
    "\n",
    "##############\n",
    "# Test dataset\n",
    "##############\n",
    "test_encoded_attr_list = []\n",
    "for enc in encoded_attr_list:\n",
    "    col_name = enc['col_name']\n",
    "    le = enc['label_enc']\n",
    "    ohe = enc['ohe_enc']\n",
    "    test_encoded_attr_list.append({'feature_df':transform_ohe(X_test,\n",
    "                                                              le,ohe,\n",
    "                                                              col_name),\n",
    "                                   'col_name':col_name})\n",
    "    \n",
    "    \n",
    "test_feature_df_list = [X_test[numeric_feature_cols]]\n",
    "test_feature_df_list.extend([enc['feature_df'] \\\n",
    "                             for enc in test_encoded_attr_list \\\n",
    "                             if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "test_df_new = pd.concat(test_feature_df_list, axis=1) \n",
    "print(\"Test dataset shape::{}\".format(test_df_new.shape))\n",
    "print(test_df_new.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594c0ec-5dd8-4631-b3c1-61f476f6a4f3",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993953b9-37f6-4b12-9719-99afe01a0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing train dataset\n",
    "X = train_df_new\n",
    "y= y.total_count.values.reshape(-1,1)\n",
    "\n",
    "# Constructing test dataset\n",
    "X_test = test_df_new\n",
    "y_test = y_test.total_count.values.reshape(-1,1)\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6251631-6b24-44b5-9dc3-bc5eefd08dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_split=5,\n",
    "                           max_leaf_nodes=10)\n",
    "\n",
    "dtm.fit(X,y)\n",
    "print(\"R-Squared on train dataset={}\".format(dtm.score(X_test,y_test)))\n",
    "\n",
    "dtm.fit(X_test,y_test)   \n",
    "print(\"R-Squaredon test dataset={}\".format(dtm.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92178cc2-5f52-4a52-8639-d24750544400",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3d0e4-22e6-4cd4-bf78-ffd1eaa05f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\": [\"mse\", \"mae\"],\n",
    "              \"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100],\n",
    "              }\n",
    "\n",
    "## Comment in order to publish in kaggle.\n",
    "\n",
    "grid_cv_dtm = GridSearchCV(dtm, param_grid, cv=5)\n",
    "\n",
    "grid_cv_dtm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c9f65-6804-4bf6-8b45-c708ff5377f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_dtm.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtm.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9233494-f091-45d4-8a36-eff3e8916fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=grid_cv_dtm.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b96482-76bf-4205-b4fe-e49dba42849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.pointplot(data=df[['mean_test_score',\n",
    "                           'param_max_leaf_nodes',\n",
    "                           'param_max_depth']],\n",
    "             y='mean_test_score',x='param_max_depth',\n",
    "             hue='param_max_leaf_nodes',ax=ax)\n",
    "ax.set(title=\"Effect of Depth and Leaf Nodes on Model Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ef314-e75e-4b52-a37e-ad523fa3e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating training model\n",
    "predicted = grid_cv_dtm.best_estimator_.predict(X)\n",
    "residuals = y.flatten()-predicted\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y.flatten(), residuals)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad19849-01e2-4de5-b332-de5f897b5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the training model scores\n",
    "r2_scores = cross_val_score(grid_cv_dtm.best_estimator_, X, y, cv=10)\n",
    "mse_scores = cross_val_score(grid_cv_dtm.best_estimator_, X, y, cv=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"avg R-squared::{:.3f}\".format(np.mean(r2_scores)))\n",
    "print(\"MSE::{:.3f}\".format(np.mean(mse_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6f539-0fcf-4698-8d7d-e259a963414d",
   "metadata": {},
   "source": [
    "#### Test dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ac753-dff8-4e3f-b095-fdb50eeb18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtm_model = grid_cv_dtm.best_estimator_\n",
    "\n",
    "y_pred = best_dtm_model.predict(X_test)\n",
    "residuals = y_test.flatten() - y_pred\n",
    "\n",
    "\n",
    "r2_score = best_dtm_model.score(X_test,y_test)\n",
    "print(\"R-squared:{:.3f}\".format(r2_score))\n",
    "print(\"MSE: %.2f\" % metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b454a41-a7a6-45da-9735-a7ec697bd52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ff4da-4103-4999-ae0e-c7bab2443437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d7f3b-3e03-4ba5-978e-9fd48970ec49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
